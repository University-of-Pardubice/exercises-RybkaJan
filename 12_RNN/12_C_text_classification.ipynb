{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22bc5da3-377b-4a3e-a03c-5f767d0df6b2",
   "metadata": {},
   "source": [
    "# The task of finding the sentiment from the text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16896849-269a-4fda-a01f-3967bb8b5097",
   "metadata": {},
   "source": [
    "## Dataset IMDB\n",
    "\n",
    "This is a dataset of 25,000 movie reviews from IMDB, tagged by sentiment (positive/negative). \n",
    "\n",
    "The reviews have been pre-processed and each review is coded as a list of word indexes (integers). \n",
    "\n",
    "For convenience, the words are indexed by their overall frequency in the dataset, so for example, the integer \"3\" encodes the third most frequent word in the data. \n",
    "\n",
    "This allows quick filtering operations, such as \"consider only the 10,000 most frequent words, but discard the 20 most frequent words\".\n",
    "\n",
    "By convention, \"0\" does not indicate a specific word, but is used to encode the item token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e758af7-8509-4e5f-9d1a-3a722fcf0cbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a6f69e-c7ff-42dc-9307-cb22741205c5",
   "metadata": {},
   "source": [
    "## Data loading\n",
    "To load the data, we will use the predefined function again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d59330-0174-4fb1-b464-70d4904baeac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocabulary_size = 5000\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocabulary_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13232ff-988f-41f4-a9aa-1e2a343fc38f",
   "metadata": {
    "tags": []
   },
   "source": [
    "The first training record is displayed.\n",
    "\n",
    "The input data is encoded as words according to the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2ab0e4-dc44-48cd-a65c-e59b4d4893dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print (x_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5d53f3",
   "metadata": {},
   "source": [
    "Let's see what a noodle looks like made up of words and not numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e20f116",
   "metadata": {},
   "source": [
    "First we need to download the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636a2bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_idx = imdb.get_word_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131b2859",
   "metadata": {},
   "source": [
    "Originally, the index number of the value is not a key.\n",
    "\n",
    "Therefore, it is necessary to convert the index as a key and the words as values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caab321e-28c2-4342-ad03-d8e91cb32dc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "word_idx = {i: word for word, i in word_idx.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0e5e70",
   "metadata": {},
   "source": [
    "Display text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566ac8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print([word_idx[i] for i in x_train[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ede1a1",
   "metadata": {},
   "source": [
    "The first review has 218 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a37d2b4-e68a-4424-ab86-1f5ed5d4d972",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(x_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0a4363",
   "metadata": {},
   "source": [
    "Let's find out how long the reviews are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1eb0206-9dab-4d1e-8a7d-6418ce5b1e47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Maximální délka recenze: \", len(max((x_train+x_test), key=len)))\n",
    "print(\"Minimální délka recenze: \", len(min((x_train+x_test), key=len)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894d96ef",
   "metadata": {},
   "source": [
    "Now that we know what the input data looks like, let's look at the output.\n",
    "\n",
    "The resolution can be positive (0) or negative (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5310e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e36468-e8a2-471b-9e78-aa715fd6c8f0",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "The tensorflow library has functions for working with sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77ad4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00859df0",
   "metadata": {},
   "source": [
    "We'll take the first 400 words of each review. If the review is not long enough, we fill it with a blank word or the number 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b427491-de5f-4b0e-afbe-fba6c10f2353",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_words = 400\n",
    " \n",
    "x_train = sequence.pad_sequences(x_train, maxlen=max_words)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=max_words)\n",
    " \n",
    "x_valid, y_valid = x_train[:64], y_train[:64]\n",
    "x_train_, y_train_ = x_train[64:], y_train[64:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22155f0f",
   "metadata": {},
   "source": [
    "Let's check the length of the first slice, which was originally 218 characters long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bc41ad-a900-4e54-83a6-27878217c2da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print (len(x_train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23df8da7",
   "metadata": {},
   "source": [
    "Let's take a look at the first review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20394a5-a3a1-47ef-b071-4f465617e13d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b9d44b-bd61-401e-9a7d-720e7b1b7096",
   "metadata": {},
   "source": [
    "# Simple RNN model\n",
    "For the neural network we again choose SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e8a595-2a5d-41e0-8eaa-aa1c2da964d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.layers import SimpleRNN, Dense, Embedding\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9282504f",
   "metadata": {},
   "source": [
    "We create a sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d13b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_model = Sequential(name=\"Simple_RNN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9be950",
   "metadata": {},
   "source": [
    "The first layer is Embedding, it is used to map discrete values (e.g. numeric IDs of words) into dense vectors (embeddings).\n",
    "\n",
    "It is typically used when working with text. You have a vocab_size dictionary, each word is represented by a number (an index in the dictionary).\n",
    "\n",
    "The embedding converts this number into a fixed-length output_dim vector.\n",
    "\n",
    "So instead of one-hot encoding, words are represented by a more compact, meaningful vector.\n",
    "\n",
    "It is necessary to determine the size of the embedding. In our case, we set it to 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb9ddc3-a5d8-49a4-912e-d7e3377d04a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embd_len = 32\n",
    "RNN_model.add(Embedding(vocabulary_size, embd_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ecdd87",
   "metadata": {},
   "source": [
    "Then follows the SimpleRNN network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb58693",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_model.add(SimpleRNN(128,\n",
    "                        activation='tanh',\n",
    "                        return_sequences=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ad8227",
   "metadata": {},
   "source": [
    "Last is the output Dense layer, which returns a number between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a7f8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c767c3f9",
   "metadata": {},
   "source": [
    "Representation of the neural network structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313bf9ef-b8bf-46de-901f-7110d6f27b21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RNN_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5099dd02",
   "metadata": {},
   "source": [
    "This is a two-class classification model, so we use the loss function binary_crossentropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab97dad-cbb6-44c8-8e8e-7ac5f647781c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RNN_model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fda5df",
   "metadata": {},
   "source": [
    "We let go for learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1ad7cc-1037-4e21-b2c3-d077f4d6fef5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rnn_history = RNN_model.fit(x_train_, y_train_,\n",
    "                        batch_size=64,\n",
    "                        epochs=5,\n",
    "                        verbose=1,\n",
    "                        validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b230c21",
   "metadata": {},
   "source": [
    "Save the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ed4c62-798d-4c2b-bf59-ad86aedc97f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RNN_model.save('rnn_simple.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0537a134",
   "metadata": {},
   "source": [
    "Model validation\n",
    "* the first number is the value of the cost/loss function\n",
    "* the second number is the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc7a9ab-0f17-4b80-8358-29c4f6dc9a54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RNN_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5362f9e9",
   "metadata": {},
   "source": [
    "History of learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4a907a-9668-455a-82a8-f50725e63c87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig1 = plt.figure()\n",
    "plt.plot(rnn_history.history['loss'], label='Train Loss')\n",
    "plt.plot(rnn_history.history['accuracy'], label='Train Accuracy')\n",
    "plt.legend(loc=\"right\")\n",
    "plt.title('Loss, accuracy')\n",
    "plt.ylabel('Loss, accuracy')\n",
    "plt.xlabel('Počet epoch')\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bcc926-f158-4ce6-b8f1-377cbedad3ed",
   "metadata": {},
   "source": [
    "# GRU model\n",
    "The model will be very similar, but we will replace the SimpleRNN part with GRU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7841bab-2f41-42c1-8584-7dca1996e825",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import GRU\n",
    "gru_model = Sequential(name=\"GRU_Model\")\n",
    "gru_model.add(Embedding(vocabulary_size,\n",
    "                        embd_len))\n",
    "gru_model.add(GRU(128,\n",
    "                  activation='tanh',\n",
    "                  return_sequences=False))\n",
    "gru_model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43aa99c9",
   "metadata": {},
   "source": [
    "Viewing the network structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f4981a-fa0c-4a19-be5a-a79db46c4a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9a103a",
   "metadata": {},
   "source": [
    "Training a neural GRU network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43be688a-8bcc-44c6-be5f-8548b8f22d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cd8196-6628-4651-99c3-b14061acf77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_history = gru_model.fit(x_train_, y_train_,\n",
    "                         batch_size=64,\n",
    "                         epochs=10,\n",
    "                         verbose=1,\n",
    "                         validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e0042b",
   "metadata": {},
   "source": [
    "Saving the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68199e0-62a3-4e35-9cc8-623412eef1a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gru_model.save('rnn_gru.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64f5c1d",
   "metadata": {},
   "source": [
    "Model validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1d89df-03ff-4c45-9abe-f4ed1394f5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4d3695",
   "metadata": {},
   "source": [
    "View learning history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42637a26-d013-4485-a8d0-c35289e09786",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig2 = plt.figure()                \n",
    "plt.plot(gru_history.history['loss'], label='Train Loss')\n",
    "plt.plot(gru_history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(gru_history.history['val_loss'], label='Validation Loss')\n",
    "plt.plot(gru_history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend(loc=\"right\")\n",
    "plt.title('Loss, accuracy')\n",
    "plt.ylabel('Loss, accuracy')\n",
    "plt.xlabel('Počet epoch')\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad701368-7ec7-4042-9fb7-06050c64a957",
   "metadata": {},
   "source": [
    "# LTSM model\n",
    "Let's try the LTSM model. Again, it only replaces a given part of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e16e9cb-142d-491e-88f1-9d3d26b0c325",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff639d45-e0bf-4ddb-9458-fc84d9cbf077",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = Sequential(name=\"LSTM_Model\")\n",
    "lstm_model.add(Embedding(vocabulary_size,\n",
    "                         embd_len))\n",
    "lstm_model.add(LSTM(128,\n",
    "                    activation='relu',\n",
    "                    return_sequences=False))\n",
    "lstm_model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4517d59",
   "metadata": {},
   "source": [
    "Viewing the network structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19b6e9e-c0d2-40cb-b553-92ef20b48ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccc2d59",
   "metadata": {},
   "source": [
    "Neural network training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fe7e9e-03c9-4002-b079-4b0fe67c1f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb7376e-8b44-45de-adef-d4672f2dcbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ltsm_history = lstm_model.fit(x_train_, y_train_,\n",
    "                          batch_size=64,\n",
    "                          epochs=5,\n",
    "                          verbose=1,\n",
    "                          validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3a22ce",
   "metadata": {},
   "source": [
    "Storing the trained net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a297a6-cc6f-40e5-9aa7-1744946e8be0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lstm_model.save('rnn_ltsm.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beab8f57",
   "metadata": {},
   "source": [
    "Model validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24cef97-472c-45e4-b18e-5f00e5913884",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d0ceaf",
   "metadata": {},
   "source": [
    "View learning history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7329b4ab-b2aa-409f-985f-80f2bd0fb674",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig3 = plt.figure()                \n",
    "plt.plot(ltsm_history.history['loss'], label='Train Loss')\n",
    "plt.plot(ltsm_history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(ltsm_history.history['val_loss'], label='Validation Loss')\n",
    "plt.plot(ltsm_history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend(loc=\"right\")\n",
    "plt.title('Loss, accuracy')\n",
    "plt.ylabel('Loss, accuracy')\n",
    "plt.xlabel('Počet epoch')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaccb2b2-3b1c-4b17-921c-7b2b836ba456",
   "metadata": {},
   "source": [
    "# Bi-directional LSTM Model\n",
    "For the last time we try the bi-directional LTSM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1b2968-4df7-4b1d-a602-04552eaf62ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.layers import Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d55b901-9587-41d9-94ae-e3bf655f2e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_lstm_model = Sequential(name=\"Bidirectional_LSTM\")\n",
    "bi_lstm_model.add(Embedding(vocabulary_size,\n",
    "                            embd_len))\n",
    "bi_lstm_model.add(Bidirectional(LSTM(128,\n",
    "                                     activation='tanh',\n",
    "                                     return_sequences=False)))\n",
    "bi_lstm_model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f47872",
   "metadata": {},
   "source": [
    "Listing the network structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140c0b1b-10df-4aec-abd7-25a1f47be184",
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_lstm_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ff18db",
   "metadata": {},
   "source": [
    "Network training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded023b2-6216-463c-a64f-b62ed3a29331",
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_lstm_model.compile(\n",
    "  loss=\"binary_crossentropy\",\n",
    "  optimizer='adam',\n",
    "  metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91c4604-944a-4751-a669-ca59499f1d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_lstm_history = bi_lstm_model.fit(x_train_, y_train_,\n",
    "                             batch_size=64,\n",
    "                             epochs=5,\n",
    "                             validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716c8eeb",
   "metadata": {},
   "source": [
    "Saving the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00fedf1-5ea0-4c56-b8b0-1d5a2c7b56f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bi_lstm_model.save('rnn_bi_ltsm.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0154423",
   "metadata": {},
   "source": [
    "Model validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6e2fd0-de0d-4d61-94e3-2fe6d24b2345",
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_lstm_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9219dbd",
   "metadata": {},
   "source": [
    "View learning history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f7e89e-de88-4751-9908-2bae1e94e81d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig4 = plt.figure()                \n",
    "plt.plot(bi_lstm_history.history['loss'], label='Train Loss')\n",
    "plt.plot(bi_lstm_history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(bi_lstm_history.history['val_loss'], label='Validation Loss')\n",
    "plt.plot(bi_lstm_history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend(loc=\"right\")\n",
    "plt.title('Loss, accuracy')\n",
    "plt.ylabel('Loss, accuracy')\n",
    "plt.xlabel('Počet epoch')\n",
    "plt.show() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
