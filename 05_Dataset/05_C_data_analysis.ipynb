{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data exploration and editing\n",
    "You will be demonstrating model building on freely available datasets.\n",
    "\n",
    "Very often, raw data contains errors, some data is missing, data is in the wrong format, etc.\n",
    "\n",
    "It is always a good idea to understand the data before you start working with it, and to adjust it if necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of freely available data sources on the internet that you can test your skills on.\n",
    "- https://archive.ics.uci.edu/ml/index.php\n",
    "- https://www.kaggle.com/\n",
    "- https://toolbox.google.com/datasetsearch\n",
    "- github datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Boston Housing Dataset\n",
    "\n",
    "The housing dataset is derived from housing information for the Boston, Massachusetts area collected by the U.S. Census Bureau.  \n",
    "\n",
    "The data were originally published in an article by Harrison, D. and Rubinfeld, D.L. `Hedonic prices and the demand for clean air', J. Environ. Economics & Management, vol.5, 81-102, 1978. \n",
    "\n",
    "The dataset contains information on 506 different homes in Boston.\n",
    "\n",
    "Dataset features\n",
    "* CRIM - crime rate per capita by city\n",
    "* ZN - the proportion of residential lots over 25,000 square feet.\n",
    "* INDUS - share of non-commercial business space per city\n",
    "* CHAS - Charles River dummy variable (1 if the tract borders a river; 0 otherwise)\n",
    "* NOX - nitrogen oxide concentration (parts per 10 million)\n",
    "* RM - average number of rooms per dwelling\n",
    "* AGE - percentage of owner-occupied units built before 1940\n",
    "* DIS - weighted distances to Boston's five employment centers\n",
    "* RAD - accessibility index to radial freeways\n",
    "* TAX - full property tax rate per $10,000 of assessed value\n",
    "* PTRATIO - pupil-teacher ratio by city\n",
    "* B - 1000(Bk - 0.63)^2, where Bk is the proportion of blacks in each city.\n",
    "* LSTAT - percentage of lower status population\n",
    "* MEDV - median value of owner-occupied housing in $1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data from CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv (\"..\\\\dataset\\\\HousingData.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the structure of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic data characteristics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "It is useful to have an overview of the input data before creating the model.\n",
    "This can prevent problems later on. For example, some models require specific data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic statistics of the data in columns are displayed using the **describe** function\n",
    "- number of records\n",
    "- mean value - average\n",
    "- variance\n",
    "- minimum\n",
    "- 25% percentile\n",
    "- 50% percentile - median\n",
    "- 75% percentile\n",
    "- maximum\n",
    "\n",
    "For some columns the mean and median differ significantly - CRIM, ZN\n",
    "\n",
    "For some columns, the mean and median are similar - RM\n",
    "\n",
    "This will be clearly visible when the distribution of values is displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some columns contain NULL data. We need to decide how to solve this problem.\n",
    "* Incomplete rows can be removed from the dataset\n",
    "* Problematic columns should not be input parameters to the model\n",
    "* Missing values could be produced as average, zeros, ...\n",
    "*..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Value distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the distribution of data in columns could reveal skewed, abnormal values.\n",
    "\n",
    "At the same time, some statistical methods may not work properly on atypically distributed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of the data can be well understood from the graphs.\n",
    "\n",
    "We will create a graph that combines a histogram with an estimate of the distribution function.\n",
    "\n",
    "We obtain the distribution function estimate using the seaborn library and the kernel density estimate line.\n",
    "\n",
    "From the plots, we can see that some variables have almost normal distributions (RM), while others have almost uniform distributions (NOX). \n",
    "\n",
    "Some variables have a large representation of small values and high values are almost absent in the dataset (CRIM).\n",
    "\n",
    "For some variables, we can see that the maximum values are much represented (B, TAX)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "pos = 1\n",
    "fig = plt.figure(figsize=(16,24))\n",
    "for i in data.columns:\n",
    "    ax = fig.add_subplot(7,2, pos)\n",
    "    pos = pos + 1\n",
    "    sns.histplot(data[i], ax=ax, kde=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar information can be read on the boxplot. The distribution data is not as detailed, but the chart is compact. In addition, the outliers can be read very nicely.\n",
    "\n",
    "That is why it appears very often in technical articles when you need to present data in a small space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.plot(\n",
    "    kind='box', \n",
    "    subplots=True, \n",
    "    sharey=False, \n",
    "    figsize=(15, 6)\n",
    ")\n",
    "plt.subplots_adjust(wspace=1) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relationships between variables\n",
    "There are many variables in datasets. Often there is a relationship between them. If one variable changes, another variable is likely to change.\n",
    "\n",
    "These relationships may or may not be causal. Sometimes it can be a coincidence. \n",
    "\n",
    "That's why it's a good idea to try to decipher these relationships. \n",
    "* Uncovering relationships - see if a change in one variable is related to a change in another (e.g. height and weight).\n",
    "* Redundancy - strongly correlated variables often carry the same information → it is not necessary to have both when modelling.\n",
    "* Prediction - if one variable is strongly correlated with another, we can use it to predict (e.g. age ↔ income).\n",
    "* Hidden relationships - weak or no correlation may mean that the relationship is non-linear or influenced by other factors.\n",
    "\n",
    "There are a number of methods to detect dependencies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by creating graphs for all combinations of the two functions.\n",
    "\n",
    "The human brain is trained to look for patterns. We may see a relationship at first glance. \n",
    "\n",
    "Usually we look for a graph shape that shows a mathematical curve (line, parabola, hyperbola, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.pairplot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "The graphs show that there is some direct art between RM, LSTAT and MEDV.\n",
    "\n",
    "* RM - average number of rooms per apartment (input variable)\n",
    "* LSTAT - percentage of lower population (input variable)\n",
    "* MDEV - median value of owner-occupied dwellings in $1,000 (output variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The relationships between variables were estimated by eye. But it can also be done exactically by correlation.\n",
    "\n",
    "Correlation shows us how strongly and in which direction two (or more) variables are **linearly** dependent. Note some phenomena may not have a linear dependence, but another. For other types of relationships than linear, the correlation coefficient will not work.\n",
    "\n",
    "Correlation coefficient (Pearson's r):\n",
    "* Values from -1 to 1\n",
    "* r ≈ 1 → strong positive linear dependence\n",
    "* r ≈ -1 → strong negative linear dependence\n",
    "* r ≈ 0 → no linear dependence (but may be non-linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "corr=data.corr()\n",
    "corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A strong direct or indirect correlation may indicate a relationship between input parameters.\n",
    "This can help us in choosing the input parameters of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes it can be useful to show correlations using a heatmap.\n",
    "Especially if the correlation matrix is large, the colours can help us to orient ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,8))\n",
    "sns.heatmap(corr.abs(), annot=True, vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "For example, the CHAS column (Charles River dummy variable) has no relationship to other elements.\n",
    "\n",
    "In contrast, the columns LSTAT, TAX, RAD, NOX, INDUS have relationships to other columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next class will attempt to create a statistical model that will estimate the MEDV property price based on the input parameters.\n",
    "\n",
    "We will use linear regression to do this.\n",
    "\n",
    "Focusing on the MEDV row, suitable input parameters may be the RM, LSTAT columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data editing and standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some columns contain NULL data. We need to decide how to solve this problem. \n",
    "* Incomplete rows can be removed from the data file.\n",
    "* Problem columns should not be model input parameters.\n",
    "* Records with extreme values can be excluded from the dataset. For example, because they are measurement errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print (data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data=data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes it is useful to discard data with outliers. \n",
    "We remove rows from the dataset where the median house value is greater than 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = data[~(data['MEDV'] >= 40.0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data standardization\n",
    "\n",
    "Each function has a different mean and standard deviation.\n",
    "\n",
    "It is a good practice to standardize the data before entering it into a mathematical model.\n",
    "\n",
    "Reasons:\n",
    "* to prevent some variables from dominating the model.\n",
    "* can help machine learning models converge more quickly\n",
    "* can make it easier to interpret the coefficients of a machine learning model\n",
    "\n",
    "Calculation:\n",
    "* x_new = (x - mean) / standard_deviation\n",
    "* mean = sum of (x) / number of (x)\n",
    "* standard_deviation = sqrt( sum ( (x - mean)^2 ) / count (x))\n",
    "\n",
    "We can do the standardization manually. We calculate the mean and standard deviation and adjust the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"AGE\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data[\"AGE\"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data['AGE_STD'] = (data['AGE'] - data['AGE'].mean()) / data['AGE'].std()\n",
    "data['LSTAT_STD'] = (data['LSTAT'] - data['LSTAT'].mean()) / data['LSTAT'].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the distribution charts to see how the original data has changed to the new data.\n",
    "\n",
    "The shape of the graph is identical, but the standardized graph is relatively centered around the value 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plt.figure (figsize=(10, 5))\n",
    "axes = fig.subplots (1, 2)           \n",
    "ax1 = axes[0]\n",
    "ax2 = axes[1]\n",
    "sns.histplot(data['AGE'],ax=ax1, kde=True)\n",
    "sns.histplot(data['AGE_STD'],ax=ax2, kde=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same for LSTAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plt.figure (figsize=(10, 5))\n",
    "axes = fig.subplots (1, 2)           \n",
    "ax1 = axes[0]\n",
    "ax2 = axes[1]\n",
    "sns.histplot(data['LSTAT'],ax=ax1, kde=True)\n",
    "sns.histplot(data['LSTAT_STD'],ax=ax2, kde=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
